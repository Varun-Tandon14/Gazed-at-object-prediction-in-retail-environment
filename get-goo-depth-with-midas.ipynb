{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:32:29.898921Z","iopub.execute_input":"2023-03-28T16:32:29.899473Z","iopub.status.idle":"2023-03-28T16:32:44.062380Z","shell.execute_reply.started":"2023-03-28T16:32:29.899359Z","shell.execute_reply":"2023-03-28T16:32:44.061153Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.7.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.13.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.64.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (22.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.13)\nInstalling collected packages: timm\nSuccessfully installed timm-0.6.13\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport torch\nimport matplotlib.pyplot as plt\nimport tqdm \nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport os\nimport numpy as np\nimport pandas as pd\nimport pickle\nfrom pathlib import PureWindowsPath, PurePosixPath","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:32:44.064881Z","iopub.execute_input":"2023-03-28T16:32:44.065187Z","iopub.status.idle":"2023-03-28T16:32:45.804586Z","shell.execute_reply.started":"2023-03-28T16:32:44.065159Z","shell.execute_reply":"2023-03-28T16:32:45.803616Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n\nmidas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmidas.to(device)\nmidas.eval()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:32:45.805862Z","iopub.execute_input":"2023-03-28T16:32:45.807057Z","iopub.status.idle":"2023-03-28T16:33:19.813199Z","shell.execute_reply.started":"2023-03-28T16:32:45.807017Z","shell.execute_reply":"2023-03-28T16:33:19.812213Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/intel-isl/MiDaS/archive/master.zip\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/1.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"958ad6f78b3744ca820c44bdc933224b"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DPTDepthModel(\n  (pretrained): Module(\n    (model): VisionTransformer(\n      (patch_embed): PatchEmbed(\n        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n        (norm): Identity()\n      )\n      (pos_drop): Dropout(p=0.0, inplace=False)\n      (norm_pre): Identity()\n      (blocks): Sequential(\n        (0): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (1): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (2): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (3): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (4): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (5): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (6): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (7): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (8): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (9): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (10): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (11): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (12): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (13): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (14): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (15): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (16): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (17): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (18): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (19): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (20): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (21): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (22): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (23): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n      )\n      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (fc_norm): Identity()\n      (head): Linear(in_features=1024, out_features=1000, bias=True)\n    )\n    (act_postprocess1): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n    )\n    (act_postprocess2): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n    )\n    (act_postprocess3): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (act_postprocess4): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n  )\n  (scratch): Module(\n    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (refinenet1): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (refinenet2): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (refinenet3): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (refinenet4): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (output_conv): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Interpolate()\n      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU(inplace=True)\n      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (5): ReLU(inplace=True)\n      (6): Identity()\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n\nif model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n    transform = midas_transforms.dpt_transform\nelse:\n    transform = midas_transforms.small_transform","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:33:19.814784Z","iopub.execute_input":"2023-03-28T16:33:19.815832Z","iopub.status.idle":"2023-03-28T16:33:20.148549Z","shell.execute_reply.started":"2023-03-28T16:33:19.815792Z","shell.execute_reply":"2023-03-28T16:33:20.146685Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\ninput_path = '/kaggle/input/goorealdataset/finalrealdatasetImgsV3/finalrealdatasetImgsV3'\noutput_path = '/kaggle/working/goo-real-depth'\nobj_test = pd.read_pickle('/kaggle/input/goorealdataset/valrealhumansNew.pickle', compression='infer')\ndf_rg_test = pd.DataFrame.from_records(obj_test)\nprint(len(df_rg_test))\ndf = df_rg_test\n'''\n\ninput_path = '/kaggle/input/goorealdataset/finalrealdatasetImgsV3Sparsed/finalrealdatasetImgsV3Sparsed'\noutput_path = '/kaggle/working/goo-real-sparse-depth'\nobj_test = pd.read_pickle('/kaggle/input/goorealdataset/testrealhumansSparsedNew.pickle', compression='infer')\ndf_rg_test = pd.DataFrame.from_records(obj_test)\nprint(len(df_rg_test))\ndf = df_rg_test\n\n\n'''\ninput_path = '/kaggle/input/goosynthtestdataset/goo-synth-test-images/images'\noutput_path = '/kaggle/working/goo-synth-test-depth'\nobj_test = pd.read_pickle('/kaggle/input/goosynthtestdataset/goosynth_test_v2_no_segm.pkl', compression='infer')\ndf_rg_test = pd.DataFrame.from_records(obj_test)\nprint(len(df_rg_test))\ndf = df_rg_test\n'''\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:33:20.151648Z","iopub.execute_input":"2023-03-28T16:33:20.151986Z","iopub.status.idle":"2023-03-28T16:33:20.260561Z","shell.execute_reply.started":"2023-03-28T16:33:20.151957Z","shell.execute_reply":"2023-03-28T16:33:20.259553Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1162\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"\\ninput_path = '/kaggle/input/goosynthtestdataset/goo-synth-test-images/images'\\noutput_path = '/kaggle/working/goo-synth-test-depth'\\nobj_test = pd.read_pickle('/kaggle/input/goosynthtestdataset/goosynth_test_v2_no_segm.pkl', compression='infer')\\ndf_rg_test = pd.DataFrame.from_records(obj_test)\\nprint(len(df_rg_test))\\ndf = df_rg_test\\n\""},"metadata":{}}]},{"cell_type":"code","source":"df_rg_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:33:20.262196Z","iopub.execute_input":"2023-03-28T16:33:20.262892Z","iopub.status.idle":"2023-03-28T16:33:20.453496Z","shell.execute_reply.started":"2023-03-28T16:33:20.262840Z","shell.execute_reply":"2023-03-28T16:33:20.452416Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                        filename  width  height  \\\n0   8\\cam1\\cam00001_img00524.jpg   1920    1080   \n1  15\\cam0\\cam00000_img00674.jpg   1920    1080   \n2   5\\cam0\\cam00000_img00602.jpg   1920    1080   \n3  11\\cam0\\cam00000_img00648.jpg   1920    1080   \n4   8\\cam1\\cam00001_img00534.jpg   1920    1080   \n\n                                                 ann  gaze_item  gazeIdx  \\\n0  {'bboxes': [[139.0, 60.0, 176.0, 122.0], [172....         17       41   \n1  {'bboxes': [[40.0, 149.0, 99.0, 185.0], [42.0,...         24       25   \n2  {'bboxes': [[44.0, 162.0, 69.0, 202.0], [118.0...          7       30   \n3  {'bboxes': [[109.0, 112.0, 140.0, 185.0], [171...         23       39   \n4  {'bboxes': [[139.0, 60.0, 176.0, 122.0], [172....         17       41   \n\n   gaze_cx  gaze_cy   hx   hy  \\\n0      382      329  199  156   \n1      332      182  273  128   \n2      454      226  416  239   \n3      329       99  263  193   \n4      382      329  198  156   \n\n                                                 seg  cam:  occluded  cam  \\\n0  [[379.0, 320.0], [379.0, 321.0], [380.0, 319.0...     1     False    1   \n1  [[326.0, 183.0], [326.0, 184.0], [326.0, 185.0...     0     False    0   \n2  [[446.0, 238.0], [446.0, 239.0], [446.0, 240.0...     0     False    0   \n3  [[324.0, 76.0], [324.0, 77.0], [324.0, 78.0], ...     0     False    0   \n4  [[379.0, 320.0], [379.0, 321.0], [380.0, 319.0...     1     False    1   \n\n                                  partnercam  \n0       karenlazo\\cam0\\cam00000_img00524.jpg  \n1     ronjobintan\\cam1\\cam00001_img00673.jpg  \n2  jhaezminnegayo\\cam1\\cam00001_img00601.jpg  \n3        paulayap\\cam1\\cam00001_img00647.jpg  \n4       karenlazo\\cam0\\cam00000_img00534.jpg  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>ann</th>\n      <th>gaze_item</th>\n      <th>gazeIdx</th>\n      <th>gaze_cx</th>\n      <th>gaze_cy</th>\n      <th>hx</th>\n      <th>hy</th>\n      <th>seg</th>\n      <th>cam:</th>\n      <th>occluded</th>\n      <th>cam</th>\n      <th>partnercam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8\\cam1\\cam00001_img00524.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>{'bboxes': [[139.0, 60.0, 176.0, 122.0], [172....</td>\n      <td>17</td>\n      <td>41</td>\n      <td>382</td>\n      <td>329</td>\n      <td>199</td>\n      <td>156</td>\n      <td>[[379.0, 320.0], [379.0, 321.0], [380.0, 319.0...</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>karenlazo\\cam0\\cam00000_img00524.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15\\cam0\\cam00000_img00674.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>{'bboxes': [[40.0, 149.0, 99.0, 185.0], [42.0,...</td>\n      <td>24</td>\n      <td>25</td>\n      <td>332</td>\n      <td>182</td>\n      <td>273</td>\n      <td>128</td>\n      <td>[[326.0, 183.0], [326.0, 184.0], [326.0, 185.0...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>ronjobintan\\cam1\\cam00001_img00673.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5\\cam0\\cam00000_img00602.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>{'bboxes': [[44.0, 162.0, 69.0, 202.0], [118.0...</td>\n      <td>7</td>\n      <td>30</td>\n      <td>454</td>\n      <td>226</td>\n      <td>416</td>\n      <td>239</td>\n      <td>[[446.0, 238.0], [446.0, 239.0], [446.0, 240.0...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>jhaezminnegayo\\cam1\\cam00001_img00601.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11\\cam0\\cam00000_img00648.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>{'bboxes': [[109.0, 112.0, 140.0, 185.0], [171...</td>\n      <td>23</td>\n      <td>39</td>\n      <td>329</td>\n      <td>99</td>\n      <td>263</td>\n      <td>193</td>\n      <td>[[324.0, 76.0], [324.0, 77.0], [324.0, 78.0], ...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>paulayap\\cam1\\cam00001_img00647.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8\\cam1\\cam00001_img00534.jpg</td>\n      <td>1920</td>\n      <td>1080</td>\n      <td>{'bboxes': [[139.0, 60.0, 176.0, 122.0], [172....</td>\n      <td>17</td>\n      <td>41</td>\n      <td>382</td>\n      <td>329</td>\n      <td>198</td>\n      <td>156</td>\n      <td>[[379.0, 320.0], [379.0, 321.0], [380.0, 319.0...</td>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>karenlazo\\cam0\\cam00000_img00534.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def write_depth(path, depth, grayscale = False, bits=1):\n    \"\"\"Write depth map to png file.\n    Args:\n        path (str): filepath without extension\n        depth (array): depth\n        grayscale (bool): use a grayscale colormap?\n    \"\"\"\n    if not grayscale:\n        bits = 1\n\n    if not np.isfinite(depth).all():\n        depth=np.nan_to_num(depth, nan=0.0, posinf=0.0, neginf=0.0)\n        print(\"WARNING: Non-finite depth values present\")\n\n    depth_min = depth.min()\n    depth_max = depth.max()\n\n    max_val = (2**(8*bits))-1\n\n    if depth_max - depth_min > np.finfo(\"float\").eps:\n        out = max_val * (depth - depth_min) / (depth_max - depth_min)\n    else:\n        out = np.zeros(depth.shape, dtype=depth.dtype)\n\n    if not grayscale:\n        out = cv2.applyColorMap(np.uint8(out), cv2.COLORMAP_INFERNO)\n\n    if bits == 1:\n        cv2.imwrite(path + \".png\", out.astype(\"uint8\"))\n    elif bits == 2:\n        cv2.imwrite(path + \".png\", out.astype(\"uint16\"))\n\n    return","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:33:20.454876Z","iopub.execute_input":"2023-03-28T16:33:20.455331Z","iopub.status.idle":"2023-03-28T16:33:20.464207Z","shell.execute_reply.started":"2023-03-28T16:33:20.455293Z","shell.execute_reply":"2023-03-28T16:33:20.463288Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#!rm -r /kaggle/working/\n# 932","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:33:20.465742Z","iopub.execute_input":"2023-03-28T16:33:20.466332Z","iopub.status.idle":"2023-03-28T16:33:20.473586Z","shell.execute_reply.started":"2023-03-28T16:33:20.466295Z","shell.execute_reply":"2023-03-28T16:33:20.472687Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## for goo real\n\nN = len(df)\nop_shape = (480,640)\n#op_shape = (224,224)\nfor ix in tqdm.notebook.tqdm(range(N)):\n    # Fetch dataframe row\n    row = df.iloc[ix]\n    \n    # Path magic\n    path = PureWindowsPath(row['filename']).as_posix()\n    \n    # input\n    img = Image.open(os.path.join(input_path, path))\n    img = np.array(img.convert('RGB'))\n    input_batch = transform(img).to(device)\n    with torch.no_grad():\n        prediction = midas(input_batch)\n        \n        prediction = torch.nn.functional.interpolate(\n            prediction.unsqueeze(1),\n            size=op_shape,\n            mode=\"bicubic\",\n            align_corners=False,\n        ).squeeze()\n\n    output = prediction.cpu().numpy()\n    \n    subfolder_path_str = os.path.splitext(path)[0].split(\"/\")\n    key_filename = subfolder_path_str[0]+'/'+subfolder_path_str[1]\n    # create output sub-folder\n    subfolder_path = os.path.join(output_path, key_filename)\n    os.makedirs(subfolder_path, exist_ok=True)\n    # output\n    filename = os.path.join(\n            subfolder_path, \n            os.path.splitext(os.path.basename(path))[0]\n        )\n    write_depth(filename,output,grayscale=True)\nprint(output.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:33:20.476857Z","iopub.execute_input":"2023-03-28T16:33:20.477167Z","iopub.status.idle":"2023-03-28T16:38:34.545010Z","shell.execute_reply.started":"2023-03-28T16:33:20.477141Z","shell.execute_reply":"2023-03-28T16:38:34.544012Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1162 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeb969dacd7a4ae3a195387ac7a6c6cf"}},"metadata":{}},{"name":"stdout","text":"(480, 640)\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\n## for goo synth\nN = len(df)\nop_shape = (224,224)\nfor ix in tqdm.notebook.tqdm(range(N)):\n    # Fetch dataframe row\n    row = df.iloc[ix]\n    \n    # Path magic\n    path = row['filename']\n    \n    # input\n    img = Image.open(os.path.join(input_path, path))\n    img = np.array(img.convert('RGB'))\n    input_batch = transform(img).to(device)\n    with torch.no_grad():\n        prediction = midas(input_batch)\n        \n        prediction = torch.nn.functional.interpolate(\n            prediction.unsqueeze(1),\n            size=op_shape,\n            mode=\"bicubic\",\n            align_corners=False,\n        ).squeeze()\n\n    output = prediction.cpu().numpy()\n    \n    filename = os.path.splitext(path)[0]\n    write_depth(filename,output,grayscale=True)\nprint(output.shape)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-28T16:38:34.546369Z","iopub.execute_input":"2023-03-28T16:38:34.547177Z","iopub.status.idle":"2023-03-28T16:38:34.556266Z","shell.execute_reply.started":"2023-03-28T16:38:34.547136Z","shell.execute_reply":"2023-03-28T16:38:34.555092Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\\n## for goo synth\\nN = len(df)\\nop_shape = (224,224)\\nfor ix in tqdm.notebook.tqdm(range(N)):\\n    # Fetch dataframe row\\n    row = df.iloc[ix]\\n    \\n    # Path magic\\n    path = row[\\'filename\\']\\n    \\n    # input\\n    img = Image.open(os.path.join(input_path, path))\\n    img = np.array(img.convert(\\'RGB\\'))\\n    input_batch = transform(img).to(device)\\n    with torch.no_grad():\\n        prediction = midas(input_batch)\\n        \\n        prediction = torch.nn.functional.interpolate(\\n            prediction.unsqueeze(1),\\n            size=op_shape,\\n            mode=\"bicubic\",\\n            align_corners=False,\\n        ).squeeze()\\n\\n    output = prediction.cpu().numpy()\\n    \\n    filename = os.path.splitext(path)[0]\\n    write_depth(filename,output,grayscale=True)\\nprint(output.shape)\\n'"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r goo-real-sparse-test-depth.zip /kaggle/working/\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-03-28T16:38:34.557763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'goo-real-sparse-test-depth.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}